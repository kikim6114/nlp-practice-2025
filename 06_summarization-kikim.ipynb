{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPdJ5xFwjcUg"
   },
   "source": [
    "<table align=\"left\"><tr><td>\n",
    "<a href=\"https://colab.research.google.com/github/kikim6114/NLP2024-1/blob/main/06_summarization-kikim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"코랩에서 실행하기\"/></a>\n",
    "</td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8-NJsjfCZMG"
   },
   "source": [
    "이 노트북을 코랩에서 실행하려면 Pro 버전이 필요할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 87477,
     "status": "ok",
     "timestamp": 1747774731066,
     "user": {
      "displayName": "김광일",
      "userId": "10470365924443187526"
     },
     "user_tz": -540
    },
    "id": "AGC8Bp4OJ4bw",
    "outputId": "c847f87d-7538-4df1-bbcc-237dd8123c9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'nlp-practice-2025'...\n",
      "remote: Enumerating objects: 205, done.\u001b[K\n",
      "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
      "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
      "remote: Total 205 (delta 11), reused 11 (delta 10), pack-reused 190 (from 1)\u001b[K\n",
      "Receiving objects: 100% (205/205), 29.30 MiB | 16.28 MiB/s, done.\n",
      "Resolving deltas: 100% (52/52), done.\n",
      "/content/nlp-practice-2025\n",
      "⏳ Installing base requirements ...\n",
      "✅ Base requirements installed!\n",
      "Using transformers v4.51.3\n",
      "Using datasets v2.14.4\n",
      "Using accelerate v1.6.0\n",
      "Using sentencepiece v0.2.0\n",
      "Using sacrebleu v2.5.1\n",
      "Using rouge_score\n",
      "Using nltk v3.9.1\n",
      "Using py7zr v0.22.0\n"
     ]
    }
   ],
   "source": [
    "# 코랩을 사용하지 않으면 다음 코드를 주석 처리하세요.\n",
    "# !git clone https://github.com/kikim6114/nlp-practice-2025.git\n",
    "# %cd nlp-practice-2025\n",
    "# from install import *\n",
    "# install_requirements(chapter=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5076,
     "status": "ok",
     "timestamp": 1747774761466,
     "user": {
      "displayName": "김광일",
      "userId": "10470365924443187526"
     },
     "user_tz": -540
    },
    "id": "01aJFMv0jcUl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kikim\\anaconda3\\envs\\nlp\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zqROZkPjcUl"
   },
   "source": [
    "# 5. 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTl_vP53eu7z"
   },
   "source": [
    "요약(Summarization)이 도전적 작업인 이유:\n",
    "- 긴 단락의 이해\n",
    "- 관련 내용의 추론\n",
    "- 원래 문서의 주제를 통합해 유창한 텍스트를 생성\n",
    "- 영역별 요약 방법이 다르다(예: 기사와 법률계약서의 요약 방법은 다르다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8h0GZCptjcUl"
   },
   "source": [
    "## 5.1 CNN/DailyMail 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dyeqxYiqeu70"
   },
   "source": [
    "CNN/DailyMail dataset\n",
    "- 300,000개 뉴스 기사와 요약의 쌍\n",
    "- 요약을 위해 익명화 처리되지 않은 v3.0.0 사용\n",
    "- 요약: 본문에서 추출(extractive)하지 않고 추상적(abstractive)이다.\n",
    "  - Extractive: 본문의 어떤 구간을 가져다 사용함\n",
    "  - Abstractive: 내용에 맞춰 글을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403,
     "referenced_widgets": [
      "33b2d082615143ca9c40b5b6a98e4fc8",
      "d834ca2ee2ff4cc9a80382b216caaa79",
      "ba12f39c667b4461901d191df39f4a20",
      "9ed594484a5040f38b04d95fbc8448ea",
      "114118bc4d60432eb6e5920c852c4516",
      "aebe566de65c4feba8f808129e98aa08",
      "bad8a6711b7b4290849616bbf5845888",
      "0088de2f78bb4a3aaf64536df94ff2af",
      "21218838820e479b92c8f3dbec98f7b4",
      "17cdf4fcffa243d3a3038aa4f7562562",
      "3f03d7b3f0ab448199f7e31986f98fe7"
     ]
    },
    "executionInfo": {
     "elapsed": 6337,
     "status": "error",
     "timestamp": 1747775389834,
     "user": {
      "displayName": "김광일",
      "userId": "10470365924443187526"
     },
     "user_tz": -540
    },
    "id": "KfM-0Y3qjcUl",
    "outputId": "e9889cb2-cab6-42e2-efd7-f576a921683d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09361acf2954941aa376dfc47ab72fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cnn_stories.tgz:   0%|          | 0.00/159M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82537ebebd004a85add3d50e10a30795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dailymail_stories.tgz:   0%|          | 0.00/376M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df84462f687f42cea3dc51499a2dd1f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd0d43fe26747dda3e2fc8a78ac2f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/46.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfbcb2e2b1b94e60b3256be563927e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.43M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540a0414ed5e4293a1444e61312eeef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea289d1d5ab48b6b6e3afdaa737987b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be813a67985f4f01b76f2b448ef2fa7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특성: ['article', 'highlights', 'id']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, config\n",
    "# !rm -rf {config.HF_DATASETS_CACHE}\n",
    "dataset = load_dataset(\"ccdv/cnn_dailymail\", version=\"3.0.0\", trust_remote_code=True)\n",
    "# dataset = load_dataset(\"ccdv/cnn_dailymail\", version=\"3.0.0\")  # original\n",
    "print(f\"특성: {dataset['train'].column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZRQmpqZbjcUm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기사 (500개 문자 발췌, 총 길이: 3192):\n",
      "(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has n\n",
      "\n",
      "요약 (길이: 180):\n",
      "Usain Bolt wins third gold of world championship .\n",
      "Anchors Jamaica to 4x100m relay victory .\n",
      "Eighth gold at the championships for Bolt .\n",
      "Jamaica double up in women's 4x100m relay .\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[\"train\"][1]\n",
    "print(f\"\"\"기사 (500개 문자 발췌, 총 길이: {len(sample[\"article\"])}):\"\"\")\n",
    "print(sample[\"article\"][:500])\n",
    "print(f'\\n요약 (길이: {len(sample[\"highlights\"])}):')\n",
    "print(sample[\"highlights\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bazY7Yqeu70"
   },
   "source": [
    "기사가 긴 경우, 입력 시퀀스 최대 길이가 1024인 Transformer 특성상 뒷부분의 기사에 포함된 정보는 사라진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpvI3GeJjcUm"
   },
   "source": [
    "## 6.2 텍스트 요약 파이프라인\n",
    "- 여러 트랜스포머 기반 요약 모델을 살펴보자.\n",
    "- 비교를 위해 입력의 길이가 모두 동일하도록 길이를 2000 글자로 제한한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5qqDExG9jcUn"
   },
   "outputs": [],
   "source": [
    "sample_text = dataset[\"train\"][1][\"article\"][:2000]\n",
    "# 딕셔너리에 각 모델이 생성한 요약을 저장합니다.\n",
    "summaries = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHxXimlUeu71"
   },
   "source": [
    "- 텍스트를 문장 단위로 분리하는 것이 관행이므로,\n",
    "- 좋은 성능을 갖는 NLTK 패키지를 사용하여 분할한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xacCeKxVjcUn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kikim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\kikim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "hTSruLbcjcUo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The U.S. are a country.', 'The U.N. is an organization.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"The U.S. are a country. The U.N. is an organization.\"\n",
    "sent_tokenize(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMh2QRGnjcUo"
   },
   "source": [
    "### 6.2.1 요약 기준 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYkA5SDfeu71"
   },
   "source": [
    "- 요약된 텍스트의 처음 3 문장만 가져오는 함수를 정의\n",
    "- 문장 구분은 `\\n` 문자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nAyE6oUHjcUo"
   },
   "outputs": [],
   "source": [
    "def three_sentence_summary(text):\n",
    "    return \"\\n\".join(sent_tokenize(text)[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "IAriHIE5jcUo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline': \"(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay.\\nThe fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds.\\nThe U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover.\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries[\"baseline\"] = three_sentence_summary(sample_text)\n",
    "summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnHpv24zjcUp"
   },
   "source": [
    "### 6.2.2 GPT-2\n",
    "- 입력 텍스트 끝에 `TL;DR`을 붙여서 요약을 생성하게 할 수 있다.\n",
    "- `TL;DR`: Too Long; Didn't Read (Reddit 같은 사이트에서 긴 글을 중간에 생략하는 방법으로 사용)\n",
    "- sample_text + \"\\nTL;DR:\\n\" 을 입력하여 🤗Transformers의 `pipeline()`으로 원래 기사를 재생성하는 것으로 실험을 시작한다는 것에 주목하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "yg7tBbz5jcUp"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4bbf4364a3a4567af442abed2aad0bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kikim\\anaconda3\\envs\\nlp\\lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kikim\\.cache\\huggingface\\hub\\models--gpt2-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597c2606cefb4fce996a74a26497fca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e32a264cfb49e09994dd46244e2a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb2aadfe3f74cc18bc3bd95d5e7e08c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b6d08ae50943669e23272469c6f5d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa33c17a165c4ae9b8e6ef441b8b704d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b64b6e7844f40beaa992f013e9bcbcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# 코랩의 경우 gpt2-xl을 사용하면 메모리 부족 에러가 발생합니다.\n",
    "# 대신 \"gpt\" 또는 \"gpt2-large\"로 지정하거나 코랩 프로를 사용하세요.\n",
    "pipe = pipeline(\"text-generation\", model=\"gpt2-large\")\n",
    "\n",
    "gpt2_query = sample_text + \"\\nTL;DR:\\n\"  # 프롬프트 형식을 만든다.\n",
    "pipe_out = pipe(gpt2_query, max_length=512, clean_up_tokenization_spaces=True)\n",
    "summaries[\"gpt2\"] = \"\\n\".join(\n",
    "    sent_tokenize(pipe_out[0][\"generated_text\"][len(gpt2_query) :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79xsgPT9jcUp"
   },
   "source": [
    "### 6.2.3 T5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cb3xKSwIjcUp"
   },
   "source": [
    "<img alt=\"T5\" width=\"700\" caption=\"Diagram of T5's text-to-text framework (courtesy of Colin Raffel); besides translation and summarization, the CoLA (linguistic acceptability) and STSB (semantic similarity) tasks are shown\" src=\"images/chapter06_T5.png\" id=\"T5\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZWzKYFkeu72"
   },
   "source": [
    "- T5: 모든 NLP task들을 text-to-tex 작업으로 구성하는 universal transformer 아키텍처\n",
    "- T5는 요약을 포함하는 지도 및 비지도 학습데이터로 훈련됨\n",
    "- Fine-tuning 없이 pretraining에 사용했던 프롬프트를 사용해 바로 요약, 번역 등의 작업에 사용할 수 있다.\n",
    "  - 요약 format: \"summarize: \\<ARTICLE\\>\"\n",
    "  - 번역 format: \"translate English to German: \\<TEXT\\>\"\n",
    "- 함수 `pipeline(\"summarization\", model=\"t5-large\")`는 입력을 text-to-text format으로 처리하므로 \"summarize\"를 붙일 필요가 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KozBMCtPjcUp"
   },
   "outputs": [],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"t5-large\")\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries[\"t5\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKRgrztojcUq"
   },
   "source": [
    "### 6.2.4 BART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPkY4dEVeu72"
   },
   "source": [
    "- 트랜스포머를 기반으로한 seq2seq 모델(encoder-decoder)로 구축된 denoising auto encoder\n",
    "- BERT와 GPT-2 사전훈련 방식을 결합하여 훈련\n",
    "- 사전학습 중에 BERT 류의 이전 모델들 보다 더 광범위한 노이즈 체계를 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8kE833Yeu72"
   },
   "source": [
    "<img alt=\"T5\" width=\"500\" src=\"images/chapter06_bart.png\" id=\"bart\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8UcU5Oeeu72"
   },
   "source": [
    "- 여기서는 `CNN/DailyMail`에 미세조정된 `facebook/bart-large-ccn` checkpoint를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dKPydAdujcUq"
   },
   "outputs": [],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries[\"bart\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cVEAi9JjcUq"
   },
   "source": [
    "### 6.2.5 PEGASUS\n",
    "- Zhang, Jingqing, et al. \"Pegasus: Pre-training with extracted gap-sentences for abstractive summarization.\" International conference on machine learning. PMLR, 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgHBlHFbjcUq"
   },
   "source": [
    "<img alt=\"pegasus\" width=\"700\" caption=\"Diagram of PEGASUS architecture (courtesy of Jingqing Zhang et al.)\" src=\"images/chapter06_pegasus.png\" id=\"pegasus\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqpK8mzaeu72"
   },
   "source": [
    "- 논문 제목에서 알 수 있듯이 Abstractive Summarization에 특화된 모델\n",
    "- BART와 마찬가지로 Encoder-Decoder 트랜스포머\n",
    "- Token 단위가 아닌 `Important Sentence` 단위로 masking 하고 이를 생성하는 방법(Gap Sentence Generation; GSG)으로 학습.\n",
    "- Important sentence: Document 내에서 다른 문장에 비해 전체적인 context를 잘 설명할 수 있는 문장."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n7fCGRTbjcUq"
   },
   "outputs": [],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\")\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries[\"pegasus\"] = pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yxm9cIReu73"
   },
   "source": [
    "- 이 모델은 자동 줄바꿈하는 특수 토큰이 있어 `sent_tokenize()` 함수가 필요 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWN7GnDojcUq"
   },
   "source": [
    "## 6.3 요약 결과 비교하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGEZJIlPeu73"
   },
   "source": [
    "- GPT-2는 데이터셋에서 전혀 훈련되지 않았음을 주목.\n",
    "- T5는 여러 작업 중의 하나로 이 작업을 위해 미세조정됨.\n",
    "- BART와 PEGASUS는 이 작업만을 위해 미세조정됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S7IrtSUvjcUq",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"GROUND TRUTH\")\n",
    "print(dataset[\"train\"][1][\"highlights\"])\n",
    "print(\"\")\n",
    "\n",
    "for model_name in summaries:\n",
    "    print(model_name.upper())\n",
    "    print(summaries[model_name])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPhl2itneu76"
   },
   "source": [
    "- GPT-2: **Hallucination**, **invented facts**\n",
    "- 나머지 3개 모델의 요약을 정답과 비교하면 놀랄 정도로 많이 중복되며, 그중에서 PEGASUS가 정답에 가장 가깝다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9NOUMJKeu76"
   },
   "source": [
    "실 사용 환경에 사용할 모델의 선택:\n",
    "- 몇 개의 샘플을 추가로 요약해 보는 것은 최선의 모델을 선택하는은 체계적 방법이 아니다.\n",
    "- 지표 하나를 정의하고 어떤 벤치마크 데이터셋에서 모든 모델을 평가해서 성능이 최고인 모델을 선택하는 것이 이상적이 방법이다.\n",
    "- 어떤 지표를 정의해야 텍스트 생성에 우수한 모델을 판별할 수 있을까?\n",
    "  - accuracy, recall, 그리고 precision 같은 지표는 이 작업에 적용하기 어렵다\n",
    "  - 사람이 작성한 'Gold standard' 요약마다 동의어, 다른 말로 바꿔 쓰거나, 또는 조금 다르게 작성하는 방식으로 수십개의 요약이 가능하기 때문."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBzK4BzmjcUr"
   },
   "source": [
    "## 6.4 생성된 텍스트 품질 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqYiXX08eu76"
   },
   "source": [
    "- 텍스트 생성 작업의 평가는 표준적인 분류 작업만큼 쉽지 않다.\n",
    "- 단순히 참조 문장과 후보 문장이 정확히 일치하는지 확인하는 것은 최선이 아니다.\n",
    "- 사람이 직접 작성한 \"Gold Standard\" 정답도 여러개일 수 있기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wwhhi-9jcUr"
   },
   "source": [
    "### 6.4.1 BLEU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuDntdCOeu77"
   },
   "source": [
    "- BLEU: Bilingual Evaluation Understudy\n",
    "- Papineni, Kishore, et al. \"Bleu: a method for automatic evaluation of machine translation.\" Proceedings of the 40th annual meeting of the Association for Computational Linguistics. 2002.\n",
    "- 한 개의 생성된 후보 문장 $sent$ 와 (복수의) 참조 문장 $sent'$ 사이에, 𝑛-gram들이 얼마나 일치하는지를 비교.\n",
    "- 비교 방법: 유사도(modified 𝑛-gram precision)\n",
    "- Modified 𝑛-gram Precision:\n",
    "$$p_n=\\frac{\\sum_{snt \\in C}\\sum_{n\\mathrm{gram} \\in snt'}Count_{\\mathrm{clip}}(n\\mathrm{gram})}{\\sum_{snt' \\in C}\\sum_{n\\mathrm{gram} \\in snt}Count(n\\mathrm{gram})}$$\n",
    "- Brevity 페널티 (BR)\n",
    "$$BR=\\mathrm{min}\\left(1, e^{1-l_{ref}/l_{gen}}\\right)$$\n",
    "- BLEU Score:  \n",
    "$$\\mathrm{BLEU}_N=BR \\times \\left(\\prod_{n=1}^{N}p_n\\right)^{1/N}$$\n",
    "- BLEU는 동의어를 고려하지 않으며, 유도된 식의 많은 단계에 허술함이 존재한다.\n",
    "- BLEU의 단점에 대한 참고 문헌:\n",
    "[Evaluating Text Output in NLP: BLEU at Your Own Risk](https://towardsdatascience.com/evaluating-text-output-in-nlp-bleu-at-your-own-risk-e8609665a213)\n",
    "- 텍스트가 토큰화되어야 하며, 토큰화 방법이 다르면 BLEU score도 달라질 수 있다.\n",
    "- `SacreBLEU`: 토큰화 단계를 내장시킴 -> 벤치마킹에서 선호되는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMMH_m-3eu77"
   },
   "outputs": [],
   "source": [
    "# 영문판 원본의 소스 코드 ==>  실행되나, 나중에 evaluate() 때문에 오류\n",
    "# from datasets import load_metric\n",
    "\n",
    "# bleu_metric = load_metric(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHpEGbv6eu77"
   },
   "outputs": [],
   "source": [
    "# 번역판 소스코드\n",
    "!pip install evaluate\n",
    "import evaluate\n",
    "bleu_metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bFJdMAJgjcUr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "bleu_metric.add(\n",
    "    prediction=\"the the the the the the\", reference=[\"the cat is on the mat\"])\n",
    "results = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\n",
    "results[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\n",
    "pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sp5yiZf7eu77"
   },
   "source": [
    "- `reference`: list를 전달하는 이유는 참조 문장이 여러개 일 수 있기 때문\n",
    "- `smooth_method`: zero precision 방지를 위한 smoothing 방법 지정(\"floor\"이면 smooth_value=0.1 이 default)\n",
    "- `smooth_value`: n-gram이 하나도 없을 때 precision이 0 이되는 것을 방지하기 위함(여기서는 0 으로 할당하여 smoothing 기능을 끔)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "69WlgjG6jcUr"
   },
   "outputs": [],
   "source": [
    "bleu_metric.add(\n",
    "    prediction=\"the cat is on mat\", reference=[\"the cat is on the mat\"])\n",
    "results = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\n",
    "results[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\n",
    "pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i9vCtyDRjcUs"
   },
   "source": [
    "### 6.4.2 ROUGE\n",
    "- Lin, Chin-Yew. \"Rouge: A package for automatic evaluation of summaries.\" Text summarization branches out. 2004.\n",
    "- 번역에서는 가능하고 적절한 모든 단어를 포함하는 번역 보다는 정확도(Precision)가 높은 번역이 선호되므로 기계번역에서는 `BLEU`가 많이 사용된다.\n",
    "- Summarization 같은 작업에서는 생성된 텍스트에 모든 중요한 정보가 포함되기를 원하므로, 재현율(Recall)이 높기를 원하며, 이런 경우 `ROUGE`가 사용된다.\n",
    "- BLEU: 후보 문장의 n-gram이 참조 문장에 얼마나 많이 등장하는지 확인\n",
    "- ROUGE: 참조 문장의 n-gram이 후보 문장에 얼마나 많이 등장하는지 확인 <br>\n",
    "<br>\n",
    "$$\\mathrm{ROUGE}_N=\\frac{\\sum_{snt' \\in C}\\sum_{n\\mathrm{gram} \\in snt'}Count_{\\mathrm{match}}(n\\mathrm{gram})}{\\sum_{snt' \\in C}\\sum_{n\\mathrm{gram} \\in snt'}Count(n\\mathrm{gram})}$$\n",
    "<br>\n",
    "- ROUGE-L: 가장 긴 공통 부분 시퀀스(LCS: Longest Common Subsequence)를 측정하는 지표\n",
    "- 두 샘플을 비교할 때 긴 문장이 유리하므로 어떤 식으로든 정규화가 필요하다. 이를 위해 F-score 같은 방식으로 $F_{LCS}$를 사용한다.\n",
    "  - m: 참조 문장의 길이\n",
    "  - n: 후보 문장의 길이\n",
    "$$R_{LCS}=\\frac{LCS(X, Y)}{m}$$\n",
    "$$P_{LCS}=\\frac{LCS(X, Y)}{n}$$\n",
    "\n",
    "$$F_{LCS}=\\frac{{(1+\\beta^2)R_{LCS}P_{LCS}}}{R_{LCS}+\\beta^2P_{LCS}}, \\mathrm{\\qquad where}\\quad \\beta=\\frac{P_{LCS}}{R_{LCS}}$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFMz8QaVeu77"
   },
   "source": [
    "🤗Datasets에서 제공하는 ROUGE 점수 종류:\n",
    "- ROUGE-L: 문장마다 점수를 계산해서 요약에 대해 평균한 점수\n",
    "- ROUGE-Lsum: 전체 요약에 대해 직접 계산한 점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ejIkuSU8jcUs"
   },
   "outputs": [],
   "source": [
    "rouge_metric = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C68XR0QwjcUs"
   },
   "outputs": [],
   "source": [
    "reference = dataset[\"train\"][1][\"highlights\"]\n",
    "records = []\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "\n",
    "for model_name in summaries:\n",
    "    rouge_metric.add(prediction=summaries[model_name], reference=reference)\n",
    "    score = rouge_metric.compute()\n",
    "    rouge_dict = dict((rn, score[rn]) for rn in rouge_names)\n",
    "    records.append(rouge_dict)\n",
    "pd.DataFrame.from_records(records, index=summaries.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKWlU7I1eu77"
   },
   "source": [
    "PEGASUS 논문에 따르면, CNN/DaylyMail 데이터셋에서 T5 보다 뛰어나며, 적어도 BART에 견줄만 하다고 주장. PEGASUS 논문의 결과가 재현되는지 살펴보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8BeErS6qjcUs"
   },
   "source": [
    "## 6.5 CNN/DailyMail 데이터셋에서 PEGASUS 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKJIoeCLeu78"
   },
   "source": [
    "노트북 중간부터 실행하는 경우에만 다음 Cell을 실행할 것!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ayYWw-z4jcUs"
   },
   "outputs": [],
   "source": [
    "# 이 셀은 노트북 중간부터 실행하기 위한 것입니다. 실행하려면 주석처리를 삭제하자\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# \"cnn_dailymail\" 데이터셋 다운로드 에러가 발생할 경우 대신 \"ccdv/cnn_dailymail\"을 사용하세요.\n",
    "dataset = load_dataset(\"ccdv/cnn_dailymail\", version=\"3.0.0\")\n",
    "rouge_metric = evaluate.load(\"rouge\", cache_dir=None)\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHLX0Rfueu78"
   },
   "source": [
    "- 이제 모델을 적절히 평가할 요소를 모두 갖췄다.\n",
    "- 우선 처음 세 문장을 사용하는 baseline model의 성능부터 평가하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aToVS3ZKjcUs"
   },
   "outputs": [],
   "source": [
    "def evaluate_summaries_baseline(dataset, metric,\n",
    "                                column_text=\"article\",\n",
    "                                column_summary=\"highlights\"):\n",
    "    summaries = [three_sentence_summary(text) for text in dataset[column_text]]\n",
    "    metric.add_batch(predictions=summaries,\n",
    "                     references=dataset[column_summary])\n",
    "    score = metric.compute()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nje8xa5xeu78"
   },
   "source": [
    "- CNN/DaylyMail 데이터셋의 테스트셋의 샘플수 = ~10,000 개\n",
    "- 요약 생성에는 많은 시간이 걸린다.\n",
    "  - 생성되는 모든 토큰이 forward pass를 거쳐야 하므로\n",
    "  - 샘플마다 100개의 토큰을 생성하려면 100 x 10000 = 1백만번의 forward pass를 거쳐야 함.\n",
    "- 원래 저자의 책에는 시간을 줄이기 위해 테스트셋에서 1000개을 샘플링하여 사용.\n",
    "- 실습에서는 시간을 더 줄이기 위해 200개만 사용하기로 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVoNhsBfeu78"
   },
   "source": [
    "우선 baseline 모델 평가."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ycmRh13IjcUt"
   },
   "outputs": [],
   "source": [
    "test_sampled = dataset[\"test\"].shuffle(seed=42).select(range(200))  # 1000을 200으로 수정 - kikim6114\n",
    "\n",
    "score = evaluate_summaries_baseline(test_sampled, rouge_metric)\n",
    "rouge_dict = dict((rn, score[rn]) for rn in rouge_names)\n",
    "pd.DataFrame.from_dict(rouge_dict, orient=\"index\", columns=[\"baseline\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhXWGR8Xeu78"
   },
   "source": [
    "PEGASUS 모델 평가를 위한 함수:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uW1yflZTjcUt"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def chunks(list_of_elements, batch_size):\n",
    "    \"\"\"list_of_elements로부터 batch_size 크기의 청크를 연속적으로 생성합니다\"\"\"\n",
    "    for i in range(0, len(list_of_elements), batch_size):\n",
    "        yield list_of_elements[i : i + batch_size]\n",
    "\n",
    "def evaluate_summaries_pegasus(dataset, metric, model, tokenizer,\n",
    "                               batch_size=16, device=device,\n",
    "                               column_text=\"article\",\n",
    "                               column_summary=\"highlights\"):\n",
    "    article_batches = list(chunks(dataset[column_text], batch_size))\n",
    "    target_batches = list(chunks(dataset[column_summary], batch_size))\n",
    "\n",
    "    for article_batch, target_batch in tqdm(\n",
    "        zip(article_batches, target_batches), total=len(article_batches)):\n",
    "\n",
    "        inputs = tokenizer(article_batch, max_length=1024,  truncation=True,\n",
    "                        padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
    "                         attention_mask=inputs[\"attention_mask\"].to(device),\n",
    "                         length_penalty=0.8, num_beams=8, max_length=128)  # 논문과 동일한 매개변수 값 사용\n",
    "\n",
    "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
    "                                clean_up_tokenization_spaces=True)\n",
    "               for s in summaries]\n",
    "        decoded_summaries = [d.replace(\"<n>\", \" \") for d in decoded_summaries]\n",
    "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
    "\n",
    "    score = metric.compute()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jMQSvRcZeu78"
   },
   "source": [
    "이제 seq2seq 생성 작업에 사용되는 `AutoModelForSeq2SeqLM`을 사용하여 모델을 다시 로드하여 평가해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kG5LwCqKjcUt"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n",
    "score = evaluate_summaries_pegasus(test_sampled, rouge_metric,\n",
    "                                   model, tokenizer, batch_size=8)\n",
    "rouge_dict = dict((rn, score[rn]) for rn in rouge_names)\n",
    "pd.DataFrame(rouge_dict, index=[\"pegasus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0H9GihK_jcUt"
   },
   "source": [
    "## 6.6 요약 모델 훈련하기\n",
    "- 앞의 내용을 활용해 Text Summarization 모델을 직접 훈련해보자.\n",
    "- 삼성이 만든 SAMsum 데이터셋을 사용: 고객센터 대화 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7cTuWU0jcUu"
   },
   "outputs": [],
   "source": [
    "dataset_samsum = load_dataset(\"samsum\")\n",
    "split_lengths = [len(dataset_samsum[split])for split in dataset_samsum]\n",
    "\n",
    "print(f\"분할 크기: {split_lengths}\")\n",
    "print(f\"특성: {dataset_samsum['train'].column_names}\")\n",
    "print(\"\\n대화:\")\n",
    "print(dataset_samsum[\"test\"][0][\"dialogue\"])\n",
    "print(\"\\nSummary:\")\n",
    "print(dataset_samsum[\"test\"][0][\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdwrUZ1EjcUu"
   },
   "source": [
    "### 6.6.1 SAMSum에서 PEGASUS 평가하기\n",
    "- PUGASUS로 요약 파이프라인을 실행해 어떻게 출력되는지 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VXkcV0ZJjcUu"
   },
   "outputs": [],
   "source": [
    "pipe_out = pipe(dataset_samsum[\"test\"][0][\"dialogue\"])\n",
    "print(\"요약:\")\n",
    "print(pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IOvphcW2eu79"
   },
   "outputs": [],
   "source": [
    "SAMsum에서의 요약은 CNN/DailyMail에서보다 추상적이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vstjloEJjcUu"
   },
   "outputs": [],
   "source": [
    "score = evaluate_summaries_pegasus(dataset_samsum[\"test\"], rouge_metric, model,\n",
    "                                   tokenizer, column_text=\"dialogue\",\n",
    "                                   column_summary=\"summary\", batch_size=8)\n",
    "\n",
    "rouge_dict = dict((rn, score[rn]) for rn in rouge_names)\n",
    "pd.DataFrame(rouge_dict, index=[\"pegasus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XE7eApstjcUu",
    "outputId": "a752a6e6-7966-41f9-eedf-88c7db4b7c16"
   },
   "source": [
    "결과가 훌륭하지는 않지만 CNN/DailyMail 데이터셋이 SAMsum 과 크게 다르기 때문에 어느 정도 예상할 수 있는 결과다.\n",
    "훈련 전에 파이프라인을 준비하면 두 가지 잇점이 있다:\n",
    "- 훈련이 성공적인지 바로 평가가 가능\n",
    "- 기준점이 수립됨  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckdWOLreeu79",
    "outputId": "a752a6e6-7966-41f9-eedf-88c7db4b7c16"
   },
   "source": [
    "이 데이터셋에서 모델을 미세조정하면 ROUGE 점수가 바로 향상되어야 한다. 그렇지 않으면 훈련과정에 문제가 있는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xfqm_kNxjcUu"
   },
   "source": [
    "### 6.6.2 PEGASUS 미세 튜닝하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XhgbQsMFjcUu"
   },
   "outputs": [],
   "source": [
    "d_len = [len(tokenizer.encode(s)) for s in dataset_samsum[\"train\"][\"dialogue\"]]\n",
    "s_len = [len(tokenizer.encode(s)) for s in dataset_samsum[\"train\"][\"summary\"]]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3.5), sharey=True)\n",
    "axes[0].hist(d_len, bins=20, color=\"C0\", edgecolor=\"C0\")\n",
    "axes[0].set_title(\"Dialogue Token Length\")\n",
    "axes[0].set_xlabel(\"Length\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "axes[1].hist(s_len, bins=20, color=\"C0\", edgecolor=\"C0\")\n",
    "axes[1].set_title(\"Summary Token Length\")\n",
    "axes[1].set_xlabel(\"Length\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDVRa80Zeu79"
   },
   "source": [
    "- Trainer를 위한 data collator를 만들자\n",
    "  - 대화 최대 길이 = 1024\n",
    "  - 요약 최대 길이 = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDa2ktBWjcUu"
   },
   "outputs": [],
   "source": [
    "def convert_examples_to_features(example_batch):\n",
    "    input_encodings = tokenizer(example_batch[\"dialogue\"], max_length=1024,\n",
    "                                truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():  # 번역판에서는 context manager with~를 사용하지 않음\n",
    "        target_encodings = tokenizer(text_target=example_batch[\"summary\"], max_length=128,\n",
    "                                    truncation=True)\n",
    "\n",
    "    return {\"input_ids\": input_encodings[\"input_ids\"],\n",
    "            \"attention_mask\": input_encodings[\"attention_mask\"],\n",
    "            \"labels\": target_encodings[\"input_ids\"]}\n",
    "\n",
    "dataset_samsum_pt = dataset_samsum.map(convert_examples_to_features,\n",
    "                                       batched=True)\n",
    "columns = [\"input_ids\", \"labels\", \"attention_mask\"]\n",
    "dataset_samsum_pt.set_format(type=\"torch\", columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Y-mUdIXeu7-"
   },
   "source": [
    "`with tokenizer.as_target_tokenizer()`: 인코더와 디코더의 tokenizer를 구별하는 것이 중요할 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oYkcJ3M-jcUv"
   },
   "outputs": [],
   "source": [
    "# 티처 포싱(teacher forcing)\n",
    "# 텍스트 생성을 위한 디코더 입력과 레이블의 정렬\n",
    "text = ['PAD','Transformers', 'are', 'awesome', 'for', 'text', 'summarization']\n",
    "rows = []\n",
    "for i in range(len(text)-1):\n",
    "    rows.append({'step': i+1, 'decoder_input': text[:i+1], 'label': text[i+1]})\n",
    "pd.DataFrame(rows).set_index('step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kxJVzh6bjcUv"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KlubqTm4jcUv"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='pegasus-samsum', num_train_epochs=1, warmup_steps=500,\n",
    "    per_device_train_batch_size=1, per_device_eval_batch_size=1,\n",
    "    weight_decay=0.01, logging_steps=10, push_to_hub=True,\n",
    "    evaluation_strategy='steps', eval_steps=500, save_steps=1e6,\n",
    "    gradient_accumulation_steps=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyrgBHmbeu7-"
   },
   "source": [
    "- `gradient_accumulation_steps=16`: 모델이 크면 batch_size=1 로 하는데, batch가 너무 작으면 수렴하지 않는다.\n",
    "- 이 문제를 해결하기 위한 기법으로서, 16회 그래디언트가 누적되어 충분히 커지면 최적화 단계가 진행됨\n",
    "- 학습 속도는 느려지지만 GPU 메모리가 많이 절약됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_fJds7jjcUv"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ce7eFBgcjcUv"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model, args=training_args,\n",
    "                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n",
    "                  train_dataset=dataset_samsum_pt[\"train\"],\n",
    "                  eval_dataset=dataset_samsum_pt[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O92Rj1ynjcUv"
   },
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "score = evaluate_summaries_pegasus(\n",
    "    dataset_samsum[\"test\"], rouge_metric, trainer.model, tokenizer,\n",
    "    batch_size=2, column_text=\"dialogue\", column_summary=\"summary\")\n",
    "\n",
    "rouge_dict = dict((rn, score[rn]) for rn in rouge_names)\n",
    "pd.DataFrame(rouge_dict, index=[f\"pegasus\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SA-zWnwTjcUw"
   },
   "outputs": [],
   "source": [
    "trainer.push_to_hub(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3woac7eGjcUw"
   },
   "source": [
    "### 6.6.3 대화 요약 생성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7o7-6m-eu8A"
   },
   "source": [
    "Loss 값과 ROUGE 점수를 보면 CNN/DailyMail에서만 훈련한 원래 모델보다 크게 향상된 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3fRqCknWjcUw"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o4S3WJDNjcUw"
   },
   "outputs": [],
   "source": [
    "gen_kwargs = {\"length_penalty\": 0.8, \"num_beams\":8, \"max_length\": 128}\n",
    "sample_text = dataset_samsum[\"test\"][0][\"dialogue\"]\n",
    "reference = dataset_samsum[\"test\"][0][\"summary\"]\n",
    "# `haesun`를 자신의 허브 사용자 이름으로 바꾸세요.\n",
    "pipe = pipeline(\"summarization\", model=\"haesun/pegasus-samsum\")\n",
    "\n",
    "print(\"대화:\")\n",
    "print(sample_text)\n",
    "print(\"\\n참조 요약:\")\n",
    "print(reference)\n",
    "print(\"\\n모델 요약:\")\n",
    "print(pipe(sample_text, **gen_kwargs)[0][\"summary_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbJ5OjrWeu8A"
   },
   "source": [
    "- 참조 문장과 훨씬 더 비슷해졌다. 모델이 그냥 문장을 추출하지 않고 대화를 합성해서 요약을 만드는 법을 배운것 같다.\n",
    "- 실제 대화 입력에서 이 모델은 얼마나 잘 작동할까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NdavQ8oijcUw"
   },
   "outputs": [],
   "source": [
    "custom_dialogue = \"\"\"\\\n",
    "Thom: Hi guys, have you heard of transformers?\n",
    "Lewis: Yes, I used them recently!\n",
    "Leandro: Indeed, there is a great library by Hugging Face.\n",
    "Thom: I know, I helped build it ;)\n",
    "Lewis: Cool, maybe we should write a book about it. What do you think?\n",
    "Leandro: Great idea, how hard can it be?!\n",
    "Thom: I am in!\n",
    "Lewis: Awesome, let's do it together!\n",
    "\"\"\"\n",
    "print(pipe(custom_dialogue, **gen_kwargs)[0][\"summary_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTpcHZGujcUw"
   },
   "source": [
    "## 6.7 결론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xG-9-iXXeu8A"
   },
   "source": [
    "- Text Summarization은 sentiment analysis, NER, QA 같은 분류 작업들보다 몇가지 특수한 어려움이 있다.\n",
    "- BLEU나 ROUGE가 있지만 역시 사람의 판단이 가장 좋은 척도다\n",
    "- Summarization 모델로 작업을 수행할 때, 문맥 크기 보다는 긴 텍스트를 요약하는 방법에 의문을 갖게 된다.\n",
    "- OpenAI는 긴 문서에 반복적으로 모델을 적용하고 사람의 피드백을 반복 루프에 추가하여 summarization task의 scale을 확장했다.\n",
    "- Wu, Jeff, et al. \"Recursively summarizing books with human feedback.\" arXiv preprint arXiv:2109.10862 (2021)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5cyO4rcceu8A"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuClass": "premium",
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0088de2f78bb4a3aaf64536df94ff2af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "114118bc4d60432eb6e5920c852c4516": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17cdf4fcffa243d3a3038aa4f7562562": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21218838820e479b92c8f3dbec98f7b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "33b2d082615143ca9c40b5b6a98e4fc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d834ca2ee2ff4cc9a80382b216caaa79",
       "IPY_MODEL_ba12f39c667b4461901d191df39f4a20",
       "IPY_MODEL_9ed594484a5040f38b04d95fbc8448ea"
      ],
      "layout": "IPY_MODEL_114118bc4d60432eb6e5920c852c4516"
     }
    },
    "3f03d7b3f0ab448199f7e31986f98fe7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9ed594484a5040f38b04d95fbc8448ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_17cdf4fcffa243d3a3038aa4f7562562",
      "placeholder": "​",
      "style": "IPY_MODEL_3f03d7b3f0ab448199f7e31986f98fe7",
      "value": " 15.6k/15.6k [00:00&lt;00:00, 1.61MB/s]"
     }
    },
    "aebe566de65c4feba8f808129e98aa08": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba12f39c667b4461901d191df39f4a20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0088de2f78bb4a3aaf64536df94ff2af",
      "max": 15586,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_21218838820e479b92c8f3dbec98f7b4",
      "value": 15586
     }
    },
    "bad8a6711b7b4290849616bbf5845888": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d834ca2ee2ff4cc9a80382b216caaa79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aebe566de65c4feba8f808129e98aa08",
      "placeholder": "​",
      "style": "IPY_MODEL_bad8a6711b7b4290849616bbf5845888",
      "value": "Downloading readme: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
